ğŸ¤ Emotion-Aware Speech Recognition Using Whisper and SVM
This project demonstrates an emotion-aware speech recognition pipeline that transcribes audio from video files and classifies the speaker's emotion based on audio features.

ğŸ“Œ Features
Converts MP4 videos to WAV audio format.

Transcribes speech using OpenAI's Whisper model.

Extracts audio features (MFCC and Pitch) using librosa.

Predicts emotion using a simulated SVM classifier.

Outputs transcription, detected language, and speaker emotion.

ğŸ§  Model Components
Component	Description
Whisper	Used for transcribing speech and detecting language.
MFCC + Pitch Extraction	Extracts features from audio for emotion classification.
SVM Classifier	Trained on simulated data to predict emotion from audio features.
MoviePy	Converts MP4 video to WAV format for audio processing.

ğŸ› ï¸ Installation
Run the following command to install all required libraries:

bash
Copy
Edit
pip install openai-whisper librosa scikit-learn moviepy
ğŸ“ File Structure
graphql
Copy
Edit
emotion_speech_recognition/
â”‚
â”œâ”€â”€ main.py                         # Contains the full Python script
â”œâ”€â”€ angry_alex.wav                 # Output WAV audio (temporary file)
â””â”€â”€ vedio.mp4                      # Input MP4 file with speech
ğŸ§ª How It Works
Convert MP4 to WAV
Converts the input MP4 file into a WAV format audio file for processing.

Transcribe Audio
Uses the Whisper model to transcribe the spoken content and detect the language.

Extract Audio Features
Calculates MFCC and pitch features from the audio signal using librosa.

Emotion Classification
A pre-trained (simulated in this demo) SVM model classifies the emotion based on extracted features.

ğŸš€ Running the Program
In your script or notebook, simply call:

python
Copy
Edit
audio_path = "/content/drive/MyDrive/vedio.mp4"
emotion_aware_speech_recognition(audio_path)
âš ï¸ Notes
The current classifier uses random simulated data for training. For real-world accuracy, replace it with training on real emotion-labeled datasets like RAVDESS.

Make sure your MP4 file contains a valid audio stream.

angry_alex.wav is a temporary file; you can change the name or delete it after processing.

ğŸ“š Future Improvements
Replace simulated data with actual audio emotion datasets.

Use deep learning (e.g., CNNs or LSTMs) for emotion detection.

Improve feature extraction (e.g., adding Chroma, Spectral Contrast).

Extend to multi-language support or speaker identification.

ğŸ¤ Acknowledgements
OpenAI Whisper
Librosa
MoviePy
RAVDESS Dataset
